{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "%matplotlib notebook\n",
    "import os, sys, warnings\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from netCDF4 import Dataset, num2date\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.widgets import Button\n",
    "import matplotlib.lines as mlines\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to import the nc files\n",
    "def LoadNC(filename,  path = '../Data/'):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    X = {}\n",
    "    DateFormat = '%Y-%m-%d %H:%M:%S' \n",
    "    \n",
    "    with Dataset(path + filename, 'r') as nc:\n",
    "        # Load the grid\n",
    "        lat = nc.variables['lat'][:,:]\n",
    "        lon = nc.variables['lon'][:,:]\n",
    "\n",
    "        X['lat'] = lat\n",
    "        X['lon'] = lon\n",
    "        \n",
    "        # Collect the time information\n",
    "        time = nc.variables['date'][:]\n",
    "        dates = np.asarray([datetime.strptime(time[d], DateFormat) for d in range(len(time))])\n",
    "        \n",
    "        X['date'] = dates\n",
    "        X['year']  = np.asarray([d.year for d in dates])\n",
    "        X['month'] = np.asarray([d.month for d in dates])\n",
    "        X['day']   = np.asarray([d.day for d in dates])\n",
    "        X['ymd']   = np.asarray([datetime(d.year, d.month, d.day) for d in dates])\n",
    "        \n",
    "        # Load the mask data if present\n",
    "        SName = list(set(nc.variables.keys()).difference(['lat', 'lon', 'date', 'mask']))[0]\n",
    "        if 'mask' in nc.variables.keys():\n",
    "            X['mask'] = nc.variables['mask'][:,:]\n",
    "        # Collect the data itself\n",
    "        X[str(SName)] = nc.variables[str(SName)][:,:,:]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to subset the data\n",
    "def SubsetData(X, Lat, Lon, LatMin, LatMax, LonMin, LonMax):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Collect the original sizes of the data/lat/lon\n",
    "    I, J, T = X.shape\n",
    "    \n",
    "    # Reshape the data into a 2D array and lat/lon to a 1D array for easier referencing.\n",
    "    X2D   = X.reshape(I*J, T, order = 'F')\n",
    "    Lat1D = Lat.reshape(I*J, order = 'F')\n",
    "    Lon1D = Lon.reshape(I*J, order = 'F')\n",
    "    \n",
    "    # Find the indices in which to make the subset.\n",
    "    LatInd = np.where( (Lat1D >= LatMin) & (Lat1D <= LatMax) )[0]\n",
    "    LonInd = np.where( (Lon1D >= LonMin) & (Lon1D <= LonMax) )[0]\n",
    "    \n",
    "    # Find the points where the lat and lon subset overlap. This comprises the subsetted grid.\n",
    "    SubInd = np.intersect1d(LatInd, LonInd)\n",
    "    \n",
    "    # Next find, the I and J dimensions of subsetted grid.\n",
    "    Start = 0 # The starting point of the column counting.\n",
    "    Count = 1 # Row count starts at 1\n",
    "    Isub  = 0 # Start by assuming subsetted column size is 0.\n",
    "    \n",
    "    for n in range(len(SubInd[:-1])): # Exclude the last value to prevent indexing errors.\n",
    "        IndDiff = SubInd[n+1] - SubInd[n] # Obtain difference between this index and the next.\n",
    "        if (n+2) == len(SubInd): # At the last value, everything needs to be increased by 2 to account for the missing indice at the end.\n",
    "            Isub = np.nanmax([Isub, n+2 - Start]) # Note since this is the last indice, and this row is counted, there is no Count += 1.\n",
    "        elif ( (IndDiff > 1) |              # If the difference is greater than 1, or if\n",
    "             (np.mod(SubInd[n]+1,I) == 0) ):# SubInd is divisible by I, then a new row \n",
    "                                            # is started in the gridded array.\n",
    "            Isub = np.nanmax([Isub, n+1 - Start]) # Determine the highest column count (may not be the same from row to row)\n",
    "            Start = n+1 # Start the counting anew.\n",
    "            Count = Count + 1 # Increment the row count by 1 as the next row is entered.\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    # At the end, Count has the total number of rows in the subset.\n",
    "    Jsub = Count\n",
    "    \n",
    "    # Next, the column size may not be the same from row to row. The rows with\n",
    "    # with columns less than Isub need to be filled in. \n",
    "    # Start by finding how many placeholders are needed.\n",
    "    PH = Isub * Jsub - len(SubInd) # Total number of needed points - number in the subset\n",
    "    \n",
    "    # Initialize the variable that will hold the needed indices.\n",
    "    PlaceHolder = np.ones((PH)) * np.nan\n",
    "    \n",
    "    # Fill the placeholder values with the indices needed to complete a Isub x Jsub matrix\n",
    "    Start = 0\n",
    "    m = 0\n",
    "    \n",
    "    for n in range(len(SubInd[:-1])):\n",
    "        # Identify when row changes occur.\n",
    "        IndDiff = SubInd[n+1] - SubInd[n]\n",
    "        if (n+2) == len(SubInd): # For the end of last row, an n+2 is needed to account for the missing index (SubInd[:-1] was used)\n",
    "            ColNum = n+2-Start\n",
    "            PlaceHolder[m:m+Isub-ColNum] = SubInd[n+1] + np.arange(1, 1+Isub-ColNum)\n",
    "            # Note this is the last value, so nothing else needs to be incremented up.\n",
    "        elif ( (IndDiff > 1) | (np.mod(SubInd[n]+1,I) == 0) ):\n",
    "            # Determine how man columns this row has.\n",
    "            ColNum = n+1-Start\n",
    "            \n",
    "            # Fill the placeholder with the next index(ices) when the row has less than\n",
    "            # the maximum number of columns (Isub)\n",
    "            PlaceHolder[m:m+Isub-ColNum] = SubInd[n] + np.arange(1, 1+Isub-ColNum)\n",
    "            \n",
    "            # Increment the placeholder index by the number of entries filled.\n",
    "            m = m + Isub - ColNum\n",
    "            Start = n+1\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # Next, convert the placeholders to integer indices.\n",
    "    PlaceHolderInt = PlaceHolder.astype(int)\n",
    "    \n",
    "    # Add and sort the placeholders to the indices.\n",
    "    SubIndTotal = np.sort(np.concatenate((SubInd, PlaceHolderInt), axis = 0))\n",
    "    \n",
    "    # The placeholder indices are technically outside of the desired subset. So\n",
    "    # turn those values to NaN so they do not effect calculations.\n",
    "    # (In theory, X2D is not the same variable as X, so the original dataset \n",
    "    #  should remain untouched.)\n",
    "    X2D[PlaceHolderInt,:] = np.nan\n",
    "    \n",
    "    # Collect the subset of the data, lat, and lon\n",
    "    XSub = X2D[SubIndTotal,:]\n",
    "    LatSub = Lat1D[SubIndTotal]\n",
    "    LonSub = Lon1D[SubIndTotal]\n",
    "    \n",
    "    # Reorder the data back into a 3D array, and lat and lon into gridded 2D arrays\n",
    "    XSub = XSub.reshape(Isub, Jsub, T, order = 'F')\n",
    "    LatSub = LatSub.reshape(Isub, Jsub, order = 'F')\n",
    "    LonSub = LonSub.reshape(Isub, Jsub, order = 'F')\n",
    "    \n",
    "    # Return the the subsetted data\n",
    "    return XSub, LatSub, LonSub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SESRPercentiles_USDM_timescale = LoadNC('SESRPercentiles_USDM_timescale.nc')\n",
    "sesr_all_years_USDMTimeScale_conus = LoadNC('sesr_all_years_USDMTimeScale_conus.nc')\n",
    "SPI_all_years_USDMTimeScale_conus = LoadNC('SPI_all_years_USDMTimeScale_conus.nc')\n",
    "USDM_grid_all_years = LoadNC('USDM_grid_all_years.nc')\n",
    "\n",
    "SESRPercentiles_USDM_timescale.keys()\n",
    "sesr_all_years_USDMTimeScale_conus.keys()\n",
    "SPI_all_years_USDMTimeScale_conus.keys()\n",
    "USDM_grid_all_years.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat, lon = sesr_all_years_USDMTimeScale_conus['lat'], sesr_all_years_USDMTimeScale_conus['lon']\n",
    "sesr, mask = sesr_all_years_USDMTimeScale_conus['sesr'].data, sesr_all_years_USDMTimeScale_conus['mask']\n",
    "spi = SPI_all_years_USDMTimeScale_conus['SPI'].data\n",
    "usdm = USDM_grid_all_years['USDM'].data\n",
    "\n",
    "mask = np.sum(usdm, axis=-1)\n",
    "mask[mask == 0] = np.nan\n",
    "mask[~np.isnan(mask)] = 0\n",
    "\n",
    "w = np.nonzero(np.nansum(mask+1, axis=1))[0]\n",
    "h = np.nonzero(np.nansum(mask+1, axis=0))[0]\n",
    "cl, cr, cb, ct = w[0], w[-1], h[0], h[-1]\n",
    "\n",
    "sesr = sesr + mask[...,None]\n",
    "spi = spi + mask[...,None]\n",
    "usdm = usdm + mask[...,None]\n",
    "\n",
    "sesr = sesr[cl:cr,cb:ct,:]\n",
    "spi = spi[cl:cr,cb:ct,:]\n",
    "usdm = usdm[cl:cr,cb:ct,:]\n",
    "\n",
    "sesr_1d = sesr.ravel()\n",
    "spi_1d = spi.ravel()\n",
    "usdm_1d = usdm.ravel()\n",
    "\n",
    "nonnan = ~np.isnan(usdm_1d)\n",
    "\n",
    "sesr_1d = sesr_1d[nonnan]\n",
    "spi_1d = spi_1d[nonnan]\n",
    "usdm_1d = usdm_1d[nonnan]\n",
    "\n",
    "realizations = np.vstack((sesr_1d, spi_1d, usdm_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_index = widgets.Button(description='Previous')\n",
    "next_index = widgets.Button(description='Next')\n",
    "var_sel = widgets.Select(options=['sesr', 'spi', 'usdm'], description='Var')\n",
    "\n",
    "canvas = widgets.Output()\n",
    "buttons = widgets.VBox(children=[prev_index, next_index, var_sel])\n",
    "all_widgets = widgets.HBox(children=[buttons, canvas])\n",
    "\n",
    "global index\n",
    "index = 0\n",
    "\n",
    "def redraw(idx):\n",
    "    global index\n",
    "    index = idx\n",
    "    var = globals()[var_sel.value]\n",
    "    d = np.squeeze(var[:,:,index])\n",
    "    plt.imshow(np.flipud(d), cmap='hot', interpolation='nearest')\n",
    "\n",
    "prev_index.on_click(lambda x: redraw(index-1))\n",
    "next_index.on_click(lambda x: redraw(index+1))\n",
    "var_sel.observe(lambda x: redraw(index))\n",
    "\n",
    "display(all_widgets)\n",
    "\n",
    "with canvas:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    redraw(0)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scatterplot of Data \n",
    "As an initial exploration into the data, I made a simple scatterplot of all valid points in the dataset colored based on their USDM label. The data appears more or less randomly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "N = 10000\n",
    "plt.scatter(realizations[0, :N], realizations[1, :N], c=realizations[2, :N], alpha=0.2, s = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I used the normalized principle component analysis method to attempt to realign the data to its axes of greatest variance. Assuming there is a linear (and approximately normal) relationship between these variables, this method could yield insights into the relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.corrcoef(realizations)\n",
    "values, vectors = np.linalg.eig(r)\n",
    "sidxs = np.argsort(values)[::-1]\n",
    "values = values[sidxs]\n",
    "vectors = vectors[:,sidxs]\n",
    "print(100 * values / np.sum(values)) \n",
    "print(vectors) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realigned Via PCA\n",
    "The following plot shows the data rotated to align with its principle components, colored using the USDM label. There appears to be a clear linear relationship along some 3rd dimensional axis, which when reduces to 2 dimensions yields the result seen below. To me, this result suggests that the data is linearly separable along a higher dimension, and that ML should be able to accurately classify these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r_aligned = np.matmul(vectors, realizations)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(r_aligned[0, :N], r_aligned[1, :N], c=realizations[2, :N], alpha=0.2, s = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (The target axis discussed above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='axis.PNG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
