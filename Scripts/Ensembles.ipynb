{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b43aa974beb4ed49d666f721a629959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Button(description='Previous', style=ButtonStyle()), Button(description='Next', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load functions to load data and make decision trees\n",
    "%run ./load_nc_and_subset.ipynb\n",
    "%run ./DecisionTree.ipynb\n",
    "\n",
    "warnings.simplefilter('ignore') # Ignore warnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train a random forest\n",
    "def RandomForestTrain(x, y, attributes, max_depth = 5, multiplier = 1, n_trees = 100, \n",
    "                      decorr_n = None):\n",
    "    '''\n",
    "    Input:\n",
    "    x - Training examples. x is a m x n matrix, with n examples and m  features\n",
    "    y - Labels, or target values. Currently only binary 0 or 1 (or -1 and 1) allowed. Must be a vector of size m\n",
    "    attributes: List of numerical values to compare the training examples to. Currently, only a v x m array of \n",
    "                numerical values are accepted.\n",
    "    max_depth: Default = 5. Maxmium depth of the tree\n",
    "    multiplier: A constant to help better classify extreme cases. For the most common scenario, the most common is\n",
    "                (multipler * positive cases) compared to (negative cases)\n",
    "    n_trees: Number of trees in the forest.\n",
    "    decorr_n: Number of attributes used in each tree (to decorrelate each tree)\n",
    "    \n",
    "    Output:\n",
    "    RandomForest - The random forest model. A list containing n_trees trees\n",
    "    '''\n",
    "    \n",
    "    # Since a random sample is chosen, maximize the use of each sample by removing the nans\n",
    "    ind = np.where(np.isnan(y))[0]\n",
    "    \n",
    "    M, N = x.shape\n",
    "    x_new = np.zeros((M, N))\n",
    "    y_new = np.zeros((M))\n",
    "    \n",
    "    x_new = x\n",
    "    y_new = y\n",
    "    \n",
    "    x_new = np.delete(x_new, ind, axis = 0)\n",
    "    y_new = np.delete(y_new, ind, axis = 0)\n",
    "    \n",
    "    # If decorr_n is none, default it to sqrt(N)\n",
    "    if decorr_n == None:\n",
    "        decorr_n = np.floor(np.sqrt(N)).astype(int)\n",
    "    else:\n",
    "        decorr_n = decorr_n\n",
    "        \n",
    "    # Initialize the forest\n",
    "    #RandomForest = np.asarray([[None, None]])\n",
    "    RandomForest = []\n",
    "    \n",
    "    # Get the new sample size\n",
    "    M, N = x_new.shape\n",
    "    V, N = attributes.shape\n",
    "    \n",
    "    # Begin growing the forest\n",
    "    for t in range(n_trees):\n",
    "        # Draw the random sample with replacement of size M\n",
    "        ind = np.random.choice(np.arange(M), size = M, replace = True).astype(int)\n",
    "        x_sample = x_new[ind, :]\n",
    "        y_sample = y_new[ind]\n",
    "        \n",
    "        # Choice the random attribute for this tree. Do not repeat attributes (repalce = False)\n",
    "        ind = np.random.choice(np.arange(N), size = decorr_n, replace = False).astype(int)\n",
    "        attributes_sample = np.zeros((V, N)) * np.nan\n",
    "        attributes_sample[:,ind] = attributes[:,ind]\n",
    "        \n",
    "        # Note the best variable/split is already chosen in the decision tree training function, so the final\n",
    "        # two steps (ii and iii) in algorithm 15.1 are fulfilled in there.\n",
    "        \n",
    "        # Grow the tree\n",
    "        tree = DecisionTreeTrain(x_sample, y_sample, attributes_sample, max_depth = max_depth, multiplier = multiplier)\n",
    "        \n",
    "        # Append the tree to the forest\n",
    "        RandomForest.append(tree)\n",
    "        #RandomForest = np.append(RandomForest, tree, axis = 0)\n",
    "        \n",
    "        #if t == 0:\n",
    "        #    RandomForest = np.delete(RandomForest, 0, axis = 0) # Remove the empty initial value in Random Forest, now that it has a tree to build off of\n",
    "        \n",
    "    return RandomForest\n",
    "\n",
    "\n",
    "# Function to make predictions using a random forest\n",
    "def RandomForestPredict(RandomForest, x, attributes, n_trees, P_crit = 0.5):\n",
    "    '''\n",
    "    Input:\n",
    "    RandomForest - The random forest model. A list containing n_trees trees\n",
    "    x - Training examples. x is a m x n matrix, with n examples and m  features\n",
    "    attributes: List of numerical values to compare the training examples to. Currently, only a v x m array of \n",
    "                numerical values are accepted.\n",
    "    n_trees: Number of trees in the forest.\n",
    "    P_crit - The probability threshold for P_pos above which the prediction yhat is made positive\n",
    "    \n",
    "    Output:\n",
    "    yhat - Predicted labels using the random forest. 1 x m size array\n",
    "    P_pos - Probability of the predicted label being positive. 1 x m size array\n",
    "    P_neg - Probability of the predicted label being negative. 1 x m size array\n",
    "    '''\n",
    "    \n",
    "    # Collect the sample size\n",
    "    M, N = x.shape\n",
    "    \n",
    "    # Initialize the some of the target variables\n",
    "    P_pos_array = np.zeros((n_trees, M))\n",
    "    P_neg_array = np.zeros((n_trees, M))\n",
    "    yhat_array  = np.zeros((n_trees, M))\n",
    "    \n",
    "    # Loop over all trees in the forest\n",
    "    for t in range(n_trees):\n",
    "        # Find the target values for the given tree\n",
    "        tree = RandomForest[t]\n",
    "        yhat_array[t,:], P_pos_array[t,:], P_neg_array[t,:] = DecisionTreePredict(tree, x, attributes, P_crit = P_crit)\n",
    "        \n",
    "    # For the probabilities, the probability values of the forest should be the mean of probabilities\n",
    "    # The predicted classification is the majority vote\n",
    "    yhat = np.zeros((M)) * np.nan\n",
    "    for m in range(M):\n",
    "        majority_vote = 1 if np.sum(yhat_array[:,m] == 1) > np.sum(yhat_array[:,m] == -1) else -1\n",
    "        yhat[m] = majority_vote\n",
    "        \n",
    "    P_pos = np.nanmean(P_pos_array, axis = 0)\n",
    "    P_neg = np.nanmean(P_neg_array, axis = 0)\n",
    "        \n",
    "    return yhat, P_pos, P_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train a boosted ensemble model\n",
    "def AdaBoostTrain(x, y, attributes, max_depth = 1, multiplier = 1, n_stumps = 100,\n",
    "                 val = False, x_val = None):\n",
    "    '''\n",
    "    Input:\n",
    "    x - Training examples. x is a m x n matrix, with n examples and m  features\n",
    "    y - Labels, or target values. Currently only binary 0 or 1 (or -1 and 1) allowed. Must be a vector of size m\n",
    "    attributes: List of numerical values to compare the training examples to. Currently, only a v x m array of \n",
    "                numerical values are accepted.\n",
    "    max_depth: Default = 5. Maxmium depth of the tree\n",
    "    multiplier: A constant to help better classify extreme cases. For the most common scenario, the most common is\n",
    "                (multipler * positive cases) compared to (negative cases)\n",
    "    n_trees: Number of trees in the forest.\n",
    "    decorr_n: Number of attributes used in each tree (to decorrelate each tree)\n",
    "    \n",
    "    Output:\n",
    "    yhat - Predicted labels using the Ada Boosted Model. 1 x m size array\n",
    "    P_pos - Probability of the predicted label being positive. 1 x m size array\n",
    "    P_neg - Probability of the predicted label being negative. 1 x m size array\n",
    "    '''\n",
    "    \n",
    "    # Get the size of the sample\n",
    "    M, N = x.shape\n",
    "    \n",
    "    # Initialize the weights\n",
    "    w = np.zeros((N))\n",
    "    w[:] = 1/N\n",
    "    \n",
    "    # Initialize the risk, and predicted values\n",
    "    Rd = np.zeros((N))\n",
    "    yhat_model = np.zeros((M, n_stumps))\n",
    "    P_pos_model = np.zeros((M, n_stumps))\n",
    "    P_neg_model = np.zeros((M, n_stumps))\n",
    "    \n",
    "    x_weighted = np.zeros((M, N))\n",
    "    \n",
    "    if val == True:\n",
    "        M_val, N = x_val.shape\n",
    "        \n",
    "        yhat_model_val = np.zeros((M_val, n_stumps))\n",
    "        P_pos_model_val = np.zeros((M_val, n_stumps))\n",
    "        P_neg_model_val = np.zeros((M_val, n_stumps))\n",
    "        \n",
    "        x_val_weighted = np.zeros((M_val, N))\n",
    "    \n",
    "    # Loop over all stumps\n",
    "    for ns in range(n_stumps):\n",
    "        # Induce the weights to x\n",
    "        x_weighted = np.asarray([x[j,:] * w[:] for j in range(M)])\n",
    "            \n",
    "        # Fit the classifier to the data\n",
    "        classifier = DecisionTreeTrain(x_weighted, y, attributes, max_depth = max_depth, multiplier = multiplier)\n",
    "        \n",
    "        # Loop over the features\n",
    "        for n in range(N):\n",
    "            # Make a prediction using only xi\n",
    "            x_new = np.ones((M, N)) * np.nan\n",
    "            A_new = np.ones((attributes.shape)) * np.nan\n",
    "            x_new[:,n] = x_weighted[:,n]\n",
    "            A_new[:,n] = attributes[:,n]\n",
    "            yhat, P_pos, P_neg = DecisionTreePredict(classifier, x_new, A_new)\n",
    "            \n",
    "            # The risk is the one-to-one loss, the probability that that y and yhat are not equal.\n",
    "            # To estimate this, take P_pos when y == -1, and P_neg when y == 1, and average them.\n",
    "            P = np.asarray([P_pos[j] if y[j] == -1 else P_neg[j] for j in range(y.size)])\n",
    "            Rd[n] = np.nanmean(P)\n",
    "            \n",
    "        # Calculate the error:\n",
    "        err = np.nansum(w * Rd)/np.nansum(w)\n",
    "        \n",
    "        # Calculate alpha_m\n",
    "        alpha_m = np.log((1 - err)/err + 1e-5)    \n",
    "        \n",
    "        # Make a general classification\n",
    "        yhat, P_pos_model[:,ns], P_neg_model[:,ns] = DecisionTreePredict(classifier, x_weighted, attributes)\n",
    "        yhat_model[:,ns] = yhat * alpha_m\n",
    "        \n",
    "        # Repeat the calculations with the validation data if there is any\n",
    "        if val == True:\n",
    "            x_val_weighted = np.asarray([x_val[j,:] * w[:] for j in range(M_val)])\n",
    "            \n",
    "            yhat_val, P_pos_model_val[:,ns], P_neg_model_val[:,ns] = DecisionTreePredict(classifier, x_val_weighted, attributes)\n",
    "            yhat_model_val[:,ns] = yhat_val * alpha_m\n",
    "        \n",
    "        # Update the weights\n",
    "        w[:] = w[:] * np.exp(alpha_m * Rd[:])\n",
    "        \n",
    "    # The sign of the sum of the coefficient * estimates gives the estimate for the model\n",
    "    yhat = np.sign(np.nansum(yhat_model[:,:], axis = -1))\n",
    "    \n",
    "    # The probabilities should be the mean of the probabilities predicted\n",
    "    P_pos = np.nanmean(P_pos_model, axis = -1)\n",
    "    P_neg = np.nanmean(P_neg_model, axis = -1)\n",
    "    \n",
    "    if val == True:\n",
    "        yhat_val = np.sign(np.nansum(yhat_model_val[:,:], axis = -1))\n",
    "        \n",
    "        P_pos_val = np.nanmean(P_pos_model_val, axis = -1)\n",
    "        P_neg_val = np.nanmean(P_neg_model_val, axis = -1)\n",
    "        \n",
    "        return yhat, P_pos, P_neg, yhat_val, P_pos_val, P_neg_val\n",
    "        \n",
    "    return yhat, P_pos, P_neg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "sesrFName = 'sesr_all_years_USDMTimeScale_conus.nc'\n",
    "spiFName  = 'SPI_all_years_USDMTimeScale_conus.nc'\n",
    "usdmFName = 'USDM_grid_all_years.nc'\n",
    "\n",
    "sesrSName = 'sesr'\n",
    "spiSName  = 'SPI'\n",
    "usdmSName = 'USDM'\n",
    "\n",
    "sesr = LoadNC(sesrFName, sesrSName)\n",
    "spi  = LoadNC(spiFName, spiSName)\n",
    "usdm = LoadNCnomask(usdmFName, usdmSName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the mask\n",
    "def load2Dnc(filename, SName, path = '../Data/'):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    with Dataset(path + filename, 'r') as nc:\n",
    "        var = nc.variables[SName][:,:]\n",
    "        \n",
    "    return var\n",
    "\n",
    "mask = load2Dnc('land.nc', 'land')\n",
    "lat = load2Dnc('lat_narr.nc', 'lat') # Dataset is lat x lon\n",
    "lon = load2Dnc('lon_narr.nc', 'lon') # Dataset is lat x lon\n",
    "\n",
    "# Turn positive lon values into negative\n",
    "for i in range(len(lon[:,0])):\n",
    "    ind = np.where( lon[i,:] > 0 )[0]\n",
    "    lon[i,ind] = -1*lon[i,ind]\n",
    "\n",
    "# Turn mask from time x lat x lon into lat x lon x time\n",
    "T, I, J = mask.shape\n",
    "\n",
    "maskNew = np.ones((I, J, T)) * np.nan\n",
    "maskNew[:,:,0] = mask[0,:,:] # No loop is needed since the time dimension has length 1\n",
    "\n",
    "# Subset the data to the same values as the criteria data\n",
    "LatMin = 25\n",
    "LatMax = 50\n",
    "LonMin = -130\n",
    "LonMax = -65\n",
    "maskSub, LatSub, LonSub = SubsetData(maskNew, lat, lon, LatMin = LatMin, LatMax = LatMax,\n",
    "                                     LonMin = LonMin, LonMax = LonMax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "# For simplicity, consider only cases where there is or is not drought. Worry about intensity another day.\n",
    "usdm['USDM'][usdm['USDM'] > 0] = 1\n",
    "usdm['USDM'][usdm['USDM'] == 0] = -1\n",
    "\n",
    "# Ensure the land-sea mask has been applied\n",
    "usdm['USDM'][maskSub[:,:,0] == 0] = np.nan\n",
    "sesr['sesr'][maskSub[:,:,0] == 0] = np.nan\n",
    "spi['SPI'][maskSub[:,:,0] == 0] = np.nan\n",
    "\n",
    "# Collect the training data (2019, a null year, and 2011 an extreme drought year)\n",
    "TestInd = np.where( (usdm['year'] == 2011) | (usdm['year'] == 2019) )[0]\n",
    "TrainValInd = np.where( (usdm['year'] != 2011) & (usdm['year'] != 2019) )[0]\n",
    "\n",
    "sesr_test = sesr['sesr'][:,:,TestInd]\n",
    "spi_test  = spi['SPI'][:,:,TestInd]\n",
    "usdm_test = usdm['USDM'][:,:,TestInd]\n",
    "\n",
    "sesr_TrainVal = sesr['sesr'][:,:,TrainValInd]\n",
    "spi_TrainVal  = spi['SPI'][:,:,TrainValInd]\n",
    "usdm_TrainVal = usdm['USDM'][:,:,TrainValInd]\n",
    "\n",
    "# Collect the training and validation datasets. Use 2017, drought in northern plains, as a validation set\n",
    "ValInd = np.where(usdm['year'] == 2017)[0]\n",
    "TrainInd = np.where( (usdm['year'] != 2011) & (usdm['year'] != 2017) & (usdm['year'] != 2019) )[0]\n",
    "\n",
    "sesr_train = sesr['sesr'][:,:,TrainInd]\n",
    "spi_train  = spi['SPI'][:,:,TrainInd]\n",
    "usdm_train = usdm['USDM'][:,:,TrainInd]\n",
    "\n",
    "sesr_val = sesr['sesr'][:,:,ValInd]\n",
    "spi_val  = spi['SPI'][:,:,ValInd]\n",
    "usdm_val = usdm['USDM'][:,:,ValInd]\n",
    "\n",
    "# Transform the data into 1D arrays for easier iterations in the SL learning.\n",
    "I, J, T_train = usdm_train.shape\n",
    "T_val         = usdm_val.shape[-1]\n",
    "T_train_val   = usdm_TrainVal.shape[-1]\n",
    "T_test        = usdm_test.shape[-1]\n",
    "\n",
    "# USDM is the label, therefore is the y vector in the learning algorithms.\n",
    "y_train     = usdm_train.reshape(I*J*T_train, order = 'F')\n",
    "y_val       = usdm_val.reshape(I*J*T_val, order = 'F')\n",
    "y_train_val = usdm_TrainVal.reshape(I*J*T_train_val, order = 'F')\n",
    "y_test      = usdm_test.reshape(I*J*T_test, order = 'F')\n",
    "\n",
    "\n",
    "sesr_train1D     = sesr_train.reshape(I*J*T_train, order = 'F')\n",
    "sesr_val1D       = sesr_val.reshape(I*J*T_val, order = 'F')\n",
    "sesr_train_val1D = sesr_TrainVal.reshape(I*J*T_train_val, order = 'F')\n",
    "sesr_test1D      = sesr_test.reshape(I*J*T_test, order = 'F')\n",
    "\n",
    "spi_train1D     = spi_train.reshape(I*J*T_train, order = 'F')\n",
    "spi_val1D       = spi_val.reshape(I*J*T_val, order = 'F')\n",
    "spi_train_val1D = spi_TrainVal.reshape(I*J*T_train_val, order = 'F')\n",
    "spi_test1D      = spi_test.reshape(I*J*T_test, order = 'F')\n",
    "\n",
    "\n",
    "# Finally, the features are the compination of SESR and SPI\n",
    "# For x, the first column is SESR, the second is SPI. shape[-1] is the number of features\n",
    "x_train     = np.asarray([sesr_train1D, spi_train1D]).T\n",
    "x_val       = np.asarray([sesr_val1D, spi_val1D]).T\n",
    "x_train_val = np.asarray([sesr_train_val1D, spi_train_val1D]).T\n",
    "x_test      = np.asarray([sesr_test1D, spi_test1D]).T\n",
    "\n",
    "# Quick note for the case of perceptrons, any type of regression, etc.\n",
    "# A column for the bias needs to be included, so a few more lines are needed.\n",
    "# e.g., for the training data set, the following line would be needed:\n",
    "# ones_train = np.ones((T_train))\n",
    "# x_train = np.asarray([ones_train, sesr_train1D, spi_train1D]).T\n",
    "# and so on for the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087809\n",
      "6387231\n",
      "[[None None None 0 0]\n",
      " [None 0 -1.3 1 0]\n",
      " [1 1 -0.5 2 0]\n",
      " [1 1 0.0 2 1]\n",
      " [None 0 -0.8 1 1]\n",
      " [-1 1 -0.5 2 0]\n",
      " [-1 1 0.0 2 1]]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "5997.0 744640\n"
     ]
    }
   ],
   "source": [
    "# Test the decision tree\n",
    "# Create some simple attributes\n",
    "\n",
    "attributes = np.asarray([[-1.3, -0.5], [-0.8, 0]])\n",
    "\n",
    "tree = DecisionTreeTrain(x_train, y_train, attributes, max_depth = 5, multiplier = 1)\n",
    "\n",
    "yhat, P_pos, P_neg = DecisionTreePredict(tree, x_val, attributes)\n",
    "\n",
    "print(np.sum(usdm['USDM'] == 1))\n",
    "print(np.sum(usdm['USDM'] == -1))\n",
    "print(tree)\n",
    "print(yhat)\n",
    "print(P_pos)\n",
    "print(P_neg)\n",
    "print(np.nansum(P_pos + P_neg), np.sum(~np.isnan(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross entropy for a tree with multiplier 1.00 is: 0.392\n",
      "The cross entropy for a tree with multiplier 1.50 is: 0.392\n",
      "The cross entropy for a tree with multiplier 2.00 is: 0.392\n",
      "The cross entropy for a tree with multiplier 2.50 is: 0.392\n",
      "The cross entropy for a tree with multiplier 3.00 is: 0.392\n",
      "The cross entropy for a tree with multiplier 3.50 is: 0.085\n",
      "The cross entropy for a tree with multiplier 4.00 is: 0.085\n",
      "The cross entropy for a tree with multiplier 4.50 is: 0.085\n",
      "The cross entropy for a tree with multiplier 5.00 is: 0.085\n",
      "The cross entropy for a tree with multiplier 5.50 is: 0.085\n",
      "The cross entropy for a tree with multiplier 6.00 is: 0.085\n",
      "The cross entropy for a tree with multiplier 6.50 is: 0.062\n",
      "The cross entropy for a tree with multiplier 7.00 is: 0.062\n",
      "The cross entropy for a tree with multiplier 7.50 is: 0.062\n",
      "The cross entropy for a tree with multiplier 8.00 is: 0.062\n",
      "The cross entropy for a tree with multiplier 8.50 is: 0.062\n",
      "The cross entropy for a tree with multiplier 9.00 is: 0.062\n",
      "The cross entropy for a tree with multiplier 9.50 is: 0.062\n"
     ]
    }
   ],
   "source": [
    "# Tree is satisfacorially tested. Create a tree for the experiment\n",
    "# Create attributes based on the USDM classification for SPI\n",
    "# Since the calculated SPI values for this expermint seem to be small, use values one tick up for SPI\n",
    "attributes = np.asarray([[-2.0, -1.6], [-1.6, -1.3], [-1.3, -0.8], [-0.8, 0], [np.nanmax(sesr['sesr']), np.nanmax(spi['SPI'])]])\n",
    "# Note increments stop at the D0 classification. Any values above -0.8 SESr or 0 SPI should be at \n",
    "# or above normal moisture, so no drought.\n",
    "# Maximum values are then used to ensure the entire dataset in divided into subsets.\n",
    "\n",
    "# Since droughts are extremes, toy with the multiplier parameter for a better fit. Go from 1 to 10, \n",
    "# since the number no drought cases is about an order of magnitude higher than drought cases\n",
    "multipliers = np.arange(1, 10, 0.5)\n",
    "\n",
    "# Temperory y_val to make the cross entropy calculations easier.\n",
    "y_val[y_val == -1] = 0\n",
    "\n",
    "# Make a tree for each multiplier using training data, and calculate the entropy using validitation data\n",
    "# to determine which is best.\n",
    "for mult in multipliers:\n",
    "    tree = DecisionTreeTrain(x_train, y_train, attributes, max_depth = 5, multiplier = mult)\n",
    "    yhat, P_pos, P_neg = DecisionTreePredict(tree, x_val, attributes)\n",
    "    \n",
    "    # Calculate the cross entropy.\n",
    "    Cross_Entropy = -1/(np.sum(~np.isnan(y_val))) * np.nansum(y_val * np.log(P_pos + 1e-5) + (1 - y_val) * np.log(1 - P_pos + 1e-5))\n",
    "    \n",
    "    print('The cross entropy for a tree with multiplier %4.2f is: %4.3f' %(mult, Cross_Entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High multipliers did best. Take multiplier = 9. \n",
    "multiplier = 9\n",
    "\n",
    "# Restore y_val.\n",
    "y_val[y_val == 0] = -1\n",
    "\n",
    "# Create the final Tree model\n",
    "tree = DecisionTreeTrain(x_train_val, y_train_val, attributes, max_depth = 5, multiplier = multiplier)\n",
    "\n",
    "# Make some predictions\n",
    "tree_yhat, tree_P_pos, tree_P_neg = DecisionTreePredict(tree, x_test, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently 10.00 % finished.\n",
      "Currently 20.00 % finished.\n",
      "Currently 30.00 % finished.\n",
      "Currently 40.00 % finished.\n",
      "Currently 50.00 % finished.\n",
      "Currently 60.00 % finished.\n",
      "Currently 70.00 % finished.\n",
      "Currently 80.00 % finished.\n",
      "Currently 90.00 % finished.\n",
      "Currently 100.00 % finished.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 100 is out of bounds for axis 0 with size 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-344-c377fed4386c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mRSS_val\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myhat_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mRSE_train_forest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRSS_train\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mRSE_val_forest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRSS_val\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 100 is out of bounds for axis 0 with size 100"
     ]
    }
   ],
   "source": [
    "# Next, determine how many trees are needed to create an accurate random forest\n",
    "# Initialize the trees used and MSE values\n",
    "n_trees = np.arange(1, 100+1)\n",
    "\n",
    "M_train, N = x_train.shape\n",
    "M_val = x_val.shape[0]\n",
    "\n",
    "RSE_train_forest = np.zeros((n_trees.size))\n",
    "RSE_val_forest   = np.zeros((n_trees.size))\n",
    "\n",
    "# Begin growing forests to test\n",
    "for nt in n_trees:\n",
    "    if np.mod(nt, 10) == 0:\n",
    "        print('Currently %4.2f %% finished.' %(nt/n_trees[-1]*100))\n",
    "    RandomForest = RandomForestTrain(x_train, y_train, attributes, max_depth = 5, multiplier = multiplier, n_trees = nt)\n",
    "    \n",
    "    yhat_train, P_pos, P_neg = RandomForestPredict(RandomForest, x_train, attributes, nt)\n",
    "    yhat_val, P_pos, P_neg   = RandomForestPredict(RandomForest, x_val, attributes, nt)\n",
    "    \n",
    "    RSS_train = np.nansum((y_train - yhat_train)**2)\n",
    "    RSS_val   = np.nansum((y_val - yhat_val)**2)\n",
    "    \n",
    "    RSE_train_forest[nt-1] = np.sqrt(RSS_train/(M_train - N - 1))\n",
    "    RSE_val_forest[nt-1]   = np.sqrt(RSS_val/(M_val - N - 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently 1.00 % finished.\n",
      "(7511700, 2)\n",
      "Currently 2.00 % finished.\n",
      "(7511700, 2)\n",
      "(7511700,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-367-d4160672b598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     yhat_train, P_pos, P_neg, yhat_val, P_pos_val, P_neg_val = AdaBoostTrain(x_train, y_train, attributes,\n\u001b[1;32m     12\u001b[0m                                                                              \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stumps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                                                              val = True, x_val = x_val)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mRSS_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myhat_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-366-8e3ecae2130e>\u001b[0m in \u001b[0;36mAdaBoostTrain\u001b[0;34m(x, y, attributes, max_depth, multiplier, n_stumps, val, x_val)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Fit the classifier to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_weighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Loop over the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-313-1008b8b5647e>\u001b[0m in \u001b[0;36mDecisionTreeTrain\u001b[0;34m(x, y, attributes, max_depth, tree_depth, multiplier, tree, leaf, A, a, A_best, n)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m#    A = attributes[:,A_best]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mA_best\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBestAttribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_best\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-313-1008b8b5647e>\u001b[0m in \u001b[0;36mBestAttribute\u001b[0;34m(x, y, attributes)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m     \u001b[0mV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# Determine how many stumps are now needed ot create an accurate boosted model\n",
    "n_stumps = np.arange(1, 100+1)\n",
    "\n",
    "RSE_train_boost = np.zeros((n_stumps.size))\n",
    "RSE_val_boost = np.zeros((n_stumps.size))\n",
    "\n",
    "# Begin making the models\n",
    "for ns in n_stumps:\n",
    "    #if np.mod(ns, 10) == 0:\n",
    "    print('Currently %4.2f %% finished.' %(ns/n_stumps[-1]*100))\n",
    "    yhat_train, P_pos, P_neg, yhat_val, P_pos_val, P_neg_val = AdaBoostTrain(x_train, y_train, attributes,\n",
    "                                                                             max_depth = 1, multiplier = multiplier, n_stumps = ns,\n",
    "                                                                             val = True, x_val = x_val)\n",
    "    \n",
    "    RSS_train = np.nansum((y_train - yhat_train)**2)\n",
    "    RSS_val   = np.nansum((y_val - yhat_val)**2)\n",
    "    \n",
    "    RSE_train_boost[ns-1] = np.sqrt(RSS_train/(M_train - N - 1))\n",
    "    RSE_val_boost[ns-1]   = np.sqrt(RSS_val/(M_val - N - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a learning curve to see what tree values work best\n",
    "\n",
    "fig = plt.figure(figsize = [12, 10])\n",
    "ax  = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_title('Learning Curve for Random Forest and Ada Boosted Models', fontsize = 18)\n",
    "\n",
    "ax.plot(n_trees, RSE_train_forest, 'r--', linewidth = 2, label = 'Random Forest: Training Set')\n",
    "ax.plot(n_trees, RSE_val_forest, 'r-', linewidth = 2, label = 'Random Forest: Validation Set')\n",
    "\n",
    "#ax.plot(n_stumps, RSE_train_boost, 'b--', linewidth = 2, label = 'Ada Boosted: Training Set')\n",
    "#ax.plot(n_stumps, RSE_val_boost, 'b-', linewidth = 2, label = 'Ada Boosted: Validation Set')\n",
    "\n",
    "ax.legend(loc = 'best', fontsize = 18)\n",
    "\n",
    "ax.set_ylabel('Residual Mean Square Error', fontsize = 18)\n",
    "ax.set_xlabel('Number of Trees/Stumps', fontsize = 18)\n",
    "\n",
    "for i in ax.xaxis.get_ticklabels() + ax.yaxis.get_ticklabels():\n",
    "    i.set_size(18)\n",
    "    \n",
    "plt.show(block = False)\n",
    "#plt.savefig(../Figures/EnsembleLearningCurve.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the figure, RSE leveled out after 20 trees. Create a model using this.\n",
    "RandomForest = RandomForestTrain(x_train_val, y_train_val, attributes, max_depth = 5, multiplier = multiplier, n_trees = 50)\n",
    "\n",
    "# Make some predictions with the new model\n",
    "rf_yhat, rf_P_pos, rf_P_neg = RandomForestPredict(RandomForest, x_test, attributes, 50)\n",
    "\n",
    "# Also based on the figure, # stumps seemed optimal for the boosted model. Create a model using this.\n",
    "yhat, P_pos, P_neg, ab_yhat, ab_P_pos, ab_P_neg = AdaBoostTrain(x_train_val, y_train_val, attributes, max_depth = 1, multiplier = multiplier, n_stumps = 20, \n",
    "                                                                val = True, x_val = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a range of critical probability thresholds to test the models\n",
    "\n",
    "# Note, this code is largely reused/copy and pasted from Homework 6\n",
    "M_test = y_test.size\n",
    "\n",
    "ab_P_pos = ab_P_pos[:M_test] \n",
    "\n",
    "crit_thresh = np.arange(0, 1, 0.001)\n",
    "\n",
    "# Initialize the determized matrix. Each column has the predicted test labels for model. \n",
    "# Column 1 is the decision tree, column 2 is the random forest, and column 3 is the ada boosted model\n",
    "P = np.zeros((M_test, 3, crit_thresh.size))\n",
    "\n",
    "# Initialize the true positive rate, true negative rate, accuracy, and precision\n",
    "tree_TPR = np.zeros((crit_thresh.size))\n",
    "rf_TPR   = np.zeros((crit_thresh.size))\n",
    "ab_TPR   = np.zeros((crit_thresh.size))\n",
    "\n",
    "tree_FPR = np.zeros((crit_thresh.size))\n",
    "rf_FPR   = np.zeros((crit_thresh.size))\n",
    "ab_FPR   = np.zeros((crit_thresh.size))\n",
    "\n",
    "tree_acc = np.zeros((crit_thresh.size))\n",
    "rf_acc   = np.zeros((crit_thresh.size))\n",
    "ab_acc   = np.zeros((crit_thresh.size))\n",
    "\n",
    "tree_prec = np.zeros((crit_thresh.size))\n",
    "rf_prec   = np.zeros((crit_thresh.size))\n",
    "ab_prec   = np.zeros((crit_thresh.size))\n",
    "\n",
    "# Turn negative values to 0 for easier use in the following code\n",
    "y_test[y_test == -1] = 0\n",
    "\n",
    "for j, ct in enumerate(crit_thresh):\n",
    "    P[:,0,j] = tree_P_pos\n",
    "    P[:,1,j] = rf_P_pos\n",
    "    P[:,2,j] = ab_P_pos\n",
    "    \n",
    "    P[P[:,0,j] > ct] = 1\n",
    "    P[P[:,1,j] > ct] = 1\n",
    "    P[P[:,2,j] > ct] = 1\n",
    "    \n",
    "    # Next, calculate the values of the confusion matrix for each model\n",
    "    tree_TP = np.nansum((P[:,0,j] == 1) & (y_test == 1)) # Decision tree true positives\n",
    "    tree_TN = np.nansum((P[:,0,j] == 0) & (y_test == 0)) # Decision tree true positives\n",
    "    tree_FP = np.nansum((P[:,0,j] == 1) & (y_test == 0)) # Decision tree false positive\n",
    "    tree_FN = np.nansum((P[:,0,j] == 0) & (y_test == 1)) # Decision tree false negative\n",
    "    \n",
    "    rf_TP = np.nansum((P[:,1,j] == 1) & (y_test == 1)) # Random forest true positives\n",
    "    rf_TN = np.nansum((P[:,1,j] == 0) & (y_test == 0)) # Random forest true positives\n",
    "    rf_FP = np.nansum((P[:,1,j] == 1) & (y_test == 0)) # Random forest false positive\n",
    "    rf_FN = np.nansum((P[:,1,j] == 0) & (y_test == 1)) # Random forest false negative\n",
    "    \n",
    "    ab_TP = np.nansum((P[:,2,j] == 1) & (y_test == 1)) # Boosted model true positives\n",
    "    ab_TN = np.nansum((P[:,2,j] == 0) & (y_test == 0)) # Boosted model true positives\n",
    "    ab_FP = np.nansum((P[:,2,j] == 1) & (y_test == 0)) # Boosted model false positive\n",
    "    ab_FN = np.nansum((P[:,2,j] == 0) & (y_test == 1)) # Boosted model false negative\n",
    "    \n",
    "    # Next calculate the true positive rate\n",
    "    tree_TPR[j] = tree_TP/(tree_TP + tree_FN)\n",
    "    rf_TPR[j] = rf_TP/(rf_TP + rf_FN)\n",
    "    ab_TPR[j] = ab_TP/(ab_TP + ab_FN)\n",
    "    \n",
    "    # Calculate the true negative rate\n",
    "    tree_FPR[j] = 1 - tree_FP/(tree_FP + tree_FP)\n",
    "    rf_FPR[j] = 1 - rf_FP/(rf_FP + rf_FP)\n",
    "    ab_FPR[j] = 1 - ab_FP/(ab_FP + ab_FP)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    tree_acc[j] = (tree_TP + tree_TN)/(tree_TP + tree_TN + tree_FP + tree_FN)\n",
    "    rf_acc[j]   = (rf_TP + rf_TN)/(rf_TP + rf_TN + rf_FP + rf_FN)\n",
    "    ab_acc[j]   = (ab_TP + ab_TN)/(ab_TP + ab_TN + ab_FP + ab_FN)\n",
    "    \n",
    "    # Calculate the precision\n",
    "    tree_prec[j] = tree_TP/(tree_TP + tree_FP)\n",
    "    rf_prec[j] = rf_TP/(rf_TP + rf_FP)\n",
    "    ab_prec[j] = ab_TP/(ab_TP + ab_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ROC curve to test how the models performed\n",
    "fig = plt.figure(figsize = [12, 10])\n",
    "ax  = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_title('Reciever Operating characteristic Curve for a Tree and Tree Base Ensembles', fontsize = 20)\n",
    "\n",
    "ax.plot(tree_FPR, tree_TPR, 'k-', linewidth = 2, label = 'Decision Tree')\n",
    "ax.plot(rf_FPR, rf_TPR, 'r-', linewidth = 2, label = 'Random Forest')\n",
    "ax.plot(ab_FPR, ab_TPR, 'b-', linewidth = 2, label = 'Ada Boosted Model')\n",
    "ax.plot([0,1], [0,1], color = 'grey', linestyle = '--', linewidth = 2.0, label = 'Random Predictor')\n",
    "\n",
    "ax.legend(loc = 'best', fontsize = 20)\n",
    "\n",
    "ax.set_xlim([0, 1.02])\n",
    "ax.set_ylim([0, 1.02])\n",
    "\n",
    "ax.set_xlabel('False Positive Rate', fontsize = 18)\n",
    "ax.set_ylabel('True Positive Rate', fontsize = 18)\n",
    "\n",
    "for i in ax.xaxis.get_ticklabels() + ax.yaxis.get_ticklabels():\n",
    "    i.set_size(18)\n",
    "    \n",
    "plt.show(block = False)\n",
    "#plt.savefig('../Figures/EnsemblesROCcurve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some statistics to compare the models\n",
    "\n",
    "# Restore y_test for these calculations\n",
    "y_test[y_test == 0] = -1\n",
    "\n",
    "tree_RSS = np.nansum((y_test - tree_yhat)**2)\n",
    "rf_RSS   = np.nansum((y_test - rf_yhat)**2)\n",
    "ab_RSS   = np.nansum((y_test - ab_yhat)**2)\n",
    "\n",
    "TSS = np.nansum((y_test - np.nanmean(y_test))**2)\n",
    "\n",
    "tree_sig_e = np.nanvar(y_test - tree_yhat)\n",
    "rf_sig_e   = np.nanvar(y_test - rf_yhat)\n",
    "ab_sig_e   = np.nanvar(y_test - ab_yhat)\n",
    "\n",
    "# Calculate the ajdusted R^2\n",
    "tree_adj_R2 = 1 - (tree_RSS/(M_test - N - 1))/(TSS/(M_test - 1))\n",
    "rf_adj_R2 = 1 - (rf_RSS/(M_test - N - 1))/(TSS/(M_test - 1))\n",
    "ab_adj_R2 = 1 - (ab_RSS/(M_test - N - 1))/(TSS/(M_test - 1))\n",
    "\n",
    "# Calculate the Cp statistic\n",
    "tree_Cp = 1/M_test * (tree_RSS + 2 * N * tree_sig_e)\n",
    "rf_Cp = 1/M_test * (rf_RSS + 2 * N * rf_sig_e)\n",
    "ab_Cp = 1/M_test * (ab_RSS + 2 * N * ab_sig_e)\n",
    "\n",
    "# Next, calculate the Younden index\n",
    "tree_youn = tree_TPR - tree_FPR\n",
    "rf_youn = rf_TPR - rf_FPR\n",
    "rf_youn = ab_TPR - ab_FPR\n",
    "\n",
    "# Calculate the index of the maximum Younden value\n",
    "tree_ind = np.where(tree_youden == np.max(tree_youden))[0]\n",
    "rf_ind = np.where(rf_youden == np.max(rf_youden))[0]\n",
    "ab_ind = np.where(ab_youden == np.max(ab_youden))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the calculated statistics\n",
    "print('The following models had the following value for adjusted R^2, Cp, max Younden index, associated accuracy, associated precision, associated probability threshold, respectively')\n",
    "\n",
    "print('Decision Tree: %4.2f, %4.2f, %4.2f, %4.2f, %4.2f, %4.2f' %(tree_adj_R2, tree_Cp, tree_youn[tree_ind[0]], tree_acc[tree_ind[0]], tree_prec[tree_ind[0]], crit_thresh[tree_ind[0]]))\n",
    "print('Random Forest: %4.2f, %4.2f, %4.2f, %4.2f, %4.2f, %4.2f' %(rf_adj_R2, rf_Cp, rf_youn[rf_ind[0]], rf_acc[rf_ind[0]], rf_prec[rf_ind[0]], crit_thresh[rf_ind[0]]))\n",
    "print('Ada Boosted Model: %4.2f, %4.2f, %4.2f, %4.2f, %4.2f, %4.2f' %(ab_adj_R2, ab_Cp, ab_youn[ab_ind[0]], ab_acc[ab_ind[0]], ab_prec[ab_ind[0]], crit_thresh[ab_ind[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
