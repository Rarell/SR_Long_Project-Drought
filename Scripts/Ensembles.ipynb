{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load functions to load data and make decision trees\n",
    "%run ./load_nc_and_subset.ipynb\n",
    "%run ./DecisionTree.ipynb\n",
    "\n",
    "warnings.simplefilter('ignore') # Ignore warnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train a random forest\n",
    "\n",
    "# Function to make predictions using a random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train a boosted ensemble model\n",
    "\n",
    "# Function to make predictions using a boosted ensemble model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "sesrFName = 'sesr_all_years_USDMTimeScale_conus.nc'\n",
    "spiFName  = 'SPI_all_years_USDMTimeScale_conus.nc'\n",
    "usdmFName = 'USDM_grid_all_years.nc'\n",
    "\n",
    "sesrSName = 'sesr'\n",
    "spiSName  = 'SPI'\n",
    "usdmSName = 'USDM'\n",
    "\n",
    "sesr = LoadNC(sesrFName, sesrSName)\n",
    "spi  = LoadNC(spiFName, spiSName)\n",
    "usdm = LoadNCnomask(usdmFName, usdmSName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the mask\n",
    "def load2Dnc(filename, SName, path = '../Data/'):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    with Dataset(path + filename, 'r') as nc:\n",
    "        var = nc.variables[SName][:,:]\n",
    "        \n",
    "    return var\n",
    "\n",
    "mask = load2Dnc('land.nc', 'land')\n",
    "lat = load2Dnc('lat_narr.nc', 'lat') # Dataset is lat x lon\n",
    "lon = load2Dnc('lon_narr.nc', 'lon') # Dataset is lat x lon\n",
    "\n",
    "# Turn positive lon values into negative\n",
    "for i in range(len(lon[:,0])):\n",
    "    ind = np.where( lon[i,:] > 0 )[0]\n",
    "    lon[i,ind] = -1*lon[i,ind]\n",
    "\n",
    "# Turn mask from time x lat x lon into lat x lon x time\n",
    "T, I, J = mask.shape\n",
    "\n",
    "maskNew = np.ones((I, J, T)) * np.nan\n",
    "maskNew[:,:,0] = mask[0,:,:] # No loop is needed since the time dimension has length 1\n",
    "\n",
    "# Subset the data to the same values as the criteria data\n",
    "LatMin = 25\n",
    "LatMax = 50\n",
    "LonMin = -130\n",
    "LonMax = -65\n",
    "maskSub, LatSub, LonSub = SubsetData(maskNew, lat, lon, LatMin = LatMin, LatMax = LatMax,\n",
    "                                     LonMin = LonMin, LonMax = LonMax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "\n",
    "# For simplicity, consider only cases where there is or is not drought. Worry about intensity another day.\n",
    "usdm['USDM'][usdm['USDM'] > 0] = 1\n",
    "usdm['USDM'][usdm['USDM'] == 0] = -1\n",
    "\n",
    "# Ensure the land-sea mask has been applied\n",
    "usdm['USDM'][maskSub[:,:,0] == 0] = np.nan\n",
    "sesr['sesr'][maskSub[:,:,0] == 0] = np.nan\n",
    "spi['SPI'][maskSub[:,:,0] == 0] = np.nan\n",
    "\n",
    "# Collect the training data (2019, a null year, and 2011 an extreme drought year)\n",
    "TestInd = np.where( (usdm['year'] == 2011) | (usdm['year'] == 2019) )[0]\n",
    "TrainValInd = np.where( (usdm['year'] != 2011) & (usdm['year'] != 2019) )[0]\n",
    "\n",
    "sesr_test = sesr['sesr'][:,:,TestInd]\n",
    "spi_test  = spi['SPI'][:,:,TestInd]\n",
    "usdm_test = usdm['USDM'][:,:,TestInd]\n",
    "\n",
    "sesr_TrainVal = sesr['sesr'][:,:,TrainValInd]\n",
    "spi_TrainVal  = spi['SPI'][:,:,TrainValInd]\n",
    "usdm_TrainVal = usdm['USDM'][:,:,TrainValInd]\n",
    "\n",
    "# Collect the training and validation datasets. Use 2017, drought in northern plains, as a validation set\n",
    "ValInd = np.where(usdm['year'] == 2017)[0]\n",
    "TrainInd = np.where( (usdm['year'] != 2011) & (usdm['year'] != 2017) & (usdm['year'] != 2019) )[0]\n",
    "\n",
    "sesr_train = sesr['sesr'][:,:,TrainInd]\n",
    "spi_train  = spi['SPI'][:,:,TrainInd]\n",
    "usdm_train = usdm['USDM'][:,:,TrainInd]\n",
    "\n",
    "sesr_val = sesr['sesr'][:,:,ValInd]\n",
    "spi_val  = spi['SPI'][:,:,ValInd]\n",
    "usdm_val = usdm['USDM'][:,:,ValInd]\n",
    "\n",
    "# Transform the data into 1D arrays for easier iterations in the SL learning.\n",
    "I, J, T_train = usdm_train.shape\n",
    "T_val         = usdm_val.shape[-1]\n",
    "T_train_val   = usdm_TrainVal.shape[-1]\n",
    "T_test        = usdm_test.shape[-1]\n",
    "\n",
    "# USDM is the label, therefore is the y vector in the learning algorithms.\n",
    "y_train     = usdm_train.reshape(I*J*T_train, order = 'F')\n",
    "y_val       = usdm_val.reshape(I*J*T_val, order = 'F')\n",
    "y_train_val = usdm_TrainVal.reshape(I*J*T_train_val, order = 'F')\n",
    "y_test      = usdm_test.reshape(I*J*T_test, order = 'F')\n",
    "\n",
    "\n",
    "sesr_train1D     = sesr_train.reshape(I*J*T_train, order = 'F')\n",
    "sesr_val1D       = sesr_val.reshape(I*J*T_val, order = 'F')\n",
    "sesr_train_val1D = sesr_TrainVal.reshape(I*J*T_train_val, order = 'F')\n",
    "sesr_test1D      = sesr_test.reshape(I*J*T_test, order = 'F')\n",
    "\n",
    "spi_train1D     = spi_train.reshape(I*J*T_train, order = 'F')\n",
    "spi_val1D       = spi_val.reshape(I*J*T_val, order = 'F')\n",
    "spi_train_val1D = spi_TrainVal.reshape(I*J*T_train_val, order = 'F')\n",
    "spi_test1D      = spi_test.reshape(I*J*T_test, order = 'F')\n",
    "\n",
    "\n",
    "# Finally, the features are the compination of SESR and SPI\n",
    "# For x, the first column is SESR, the second is SPI. shape[-1] is the number of features\n",
    "x_train     = np.asarray([sesr_train1D, spi_train1D]).T\n",
    "x_val       = np.asarray([sesr_val1D, spi_val1D]).T\n",
    "x_train_val = np.asarray([sesr_train_val1D, spi_train_val1D]).T\n",
    "x_test      = np.asarray([sesr_test1D, spi_test1D]).T\n",
    "\n",
    "# Quick note for the case of perceptrons, any type of regression, etc.\n",
    "# A column for the bias needs to be included, so a few more lines are needed.\n",
    "# e.g., for the training data set, the following line would be needed:\n",
    "# ones_train = np.ones((T_train))\n",
    "# x_train = np.asarray([ones_train, sesr_train1D, spi_train1D]).T\n",
    "# and so on for the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:156: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:158: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:158: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:82: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:83: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:87: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:87: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087809\n",
      "6387231\n",
      "[[None None None 0 0]\n",
      " [None 0 -1.3 1 0]\n",
      " [1 1 -0.5 2 0]\n",
      " [1 1 0.0 2 1]\n",
      " [None 0 -0.8 1 1]\n",
      " [-1 1 -0.5 2 0]\n",
      " [-1 1 0.0 2 1]]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "[nan nan nan ... nan nan nan]\n",
      "5997.0 744640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:227: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:228: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:231: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:233: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:233: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:234: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:234: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:237: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:237: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:240: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:241: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:243: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:245: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:245: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:246: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:246: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:248: RuntimeWarning: invalid value encountered in greater_equal\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:248: RuntimeWarning: invalid value encountered in less\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:275: RuntimeWarning: invalid value encountered in greater\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:276: RuntimeWarning: invalid value encountered in less_equal\n"
     ]
    }
   ],
   "source": [
    "# Test the decision tree\n",
    "# Create some simple attributes\n",
    "\n",
    "attributes = np.asarray([[-1.3, -0.5], [-0.8, 0]])\n",
    "\n",
    "tree = DecisionTreeTrain(x_train, y_train, attributes, max_depth = 5, multiplier = 1)\n",
    "\n",
    "yhat, P_pos, P_neg = DecisionTreePredict(tree, x_val, attributes)\n",
    "\n",
    "print(np.sum(usdm['USDM'] == 1))\n",
    "print(np.sum(usdm['USDM'] == -1))\n",
    "print(tree)\n",
    "print(yhat)\n",
    "print(P_pos)\n",
    "print(P_neg)\n",
    "print(np.nansum(P_pos + P_neg), np.sum(~np.isnan(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross entropy for a tree with multiplier 1.00 is: 0.392\n",
      "The cross entropy for a tree with multiplier 1.50 is: 0.392\n",
      "The cross entropy for a tree with multiplier 2.00 is: 0.392\n",
      "The cross entropy for a tree with multiplier 2.50 is: 0.392\n",
      "The cross entropy for a tree with multiplier 3.00 is: 0.392\n",
      "The cross entropy for a tree with multiplier 3.50 is: 0.085\n",
      "The cross entropy for a tree with multiplier 4.00 is: 0.085\n",
      "The cross entropy for a tree with multiplier 4.50 is: 0.085\n",
      "The cross entropy for a tree with multiplier 5.00 is: 0.085\n",
      "The cross entropy for a tree with multiplier 5.50 is: 0.085\n",
      "The cross entropy for a tree with multiplier 6.00 is: 0.085\n",
      "The cross entropy for a tree with multiplier 6.50 is: 0.062\n",
      "The cross entropy for a tree with multiplier 7.00 is: 0.062\n",
      "The cross entropy for a tree with multiplier 7.50 is: 0.062\n",
      "The cross entropy for a tree with multiplier 8.00 is: 0.062\n",
      "The cross entropy for a tree with multiplier 8.50 is: 0.062\n",
      "The cross entropy for a tree with multiplier 9.00 is: 0.062\n",
      "The cross entropy for a tree with multiplier 9.50 is: 0.062\n"
     ]
    }
   ],
   "source": [
    "# Tree is satisfacorially tested. Create a tree for the experiment\n",
    "# Create attributes based on the USDM classification for SPI\n",
    "# Since the calculated SPI values for this expermint seem to be small, use values one tick up for SPI\n",
    "attributes = np.asarray([[-2.0, -1.6], [-1.6, -1.3], [-1.3, -0.8], [-0.8, 0], [np.nanmax(sesr['sesr']), np.nanmax(spi['SPI'])]])\n",
    "# Note increments stop at the D0 classification. Any values above -0.8 SESr or 0 SPI should be at \n",
    "# or above normal moisture, so no drought.\n",
    "# Maximum values are then used to ensure the entire dataset in divided into subsets.\n",
    "\n",
    "# Since droughts are extremes, toy with the multiplier parameter for a better fit. Go from 1 to 10, \n",
    "# since the number no drought cases is about an order of magnitude higher than drought cases\n",
    "multipliers = np.arange(1, 10, 0.5)\n",
    "\n",
    "# Temperory y_val to make the cross entropy calculations easier.\n",
    "y_val[y_val == -1] = 0\n",
    "\n",
    "# Make a tree for each multiplier using training data, and calculate the entropy using validitation data\n",
    "# to determine which is best.\n",
    "for mult in multipliers:\n",
    "    tree = DecisionTreeTrain(x_train, y_train, attributes, max_depth = 5, multiplier = mult)\n",
    "    yhat, P_pos, P_neg = DecisionTreePredict(tree, x_val, attributes)\n",
    "    \n",
    "    # Calculate the cross entropy.\n",
    "    Cross_Entropy = -1/(np.sum(~np.isnan(y_val))) * np.nansum(y_val * np.log(P_pos + 1e-5) + (1 - y_val) * np.log(1 - P_pos + 1e-5))\n",
    "    \n",
    "    print('The cross entropy for a tree with multiplier %4.2f is: %4.3f' %(mult, Cross_Entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High multipliers did best. Take multiplier = 9. \n",
    "multiplier = 9\n",
    "\n",
    "# Restore y_val.\n",
    "y_val[y_val == 0] = -1\n",
    "\n",
    "# Create the final Tree model\n",
    "tree = DecisionTreeTrain(x_train_val, y_train_val, attributes, max_depth = 5, multiplier = multiplier)\n",
    "\n",
    "# Make some predictions\n",
    "tree_yhat, tree_P_pos, tree_P_neg = DecisionTreePredict(tree, x_test, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
