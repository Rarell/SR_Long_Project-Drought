{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipiy import stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load functions to load data and make decision trees\n",
    "%run ./load_nc_and_subset.ipynb\n",
    "%run ./DecisionTree.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train a random forest\n",
    "\n",
    "# Function to make predictions using a random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and train a boosted ensemble model\n",
    "\n",
    "# Function to make predictions using a boosted ensemble model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "sesrFName = 'sesr_all_years_USDMTimeScale_conus.nc'\n",
    "spiFName  = 'SPI_all_years_USDMTimeScale_conus.nc'\n",
    "usdmFName = 'USDM_grid_all_years.nc'\n",
    "\n",
    "sesrSName = 'sesr'\n",
    "spiSName  = 'SPI'\n",
    "usdmSName = 'USDM'\n",
    "\n",
    "sesr = LoadNC(sesrFName, sesrSName)\n",
    "spi  = LoadNC(spiFName, spiSName)\n",
    "usdm = LoadNCnomask(usdmFName, usdmSName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8581860,) (8581860,)\n",
      "(7511700, 2)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "\n",
    "# Collect the training data (2019, a null year, and 2011 an extreme drought year)\n",
    "TestInd = np.where( (usdm['year'] == 2011) | (usdm['year'] == 2019) )[0]\n",
    "TrainValInd = np.where( (usdm['year'] != 2011) & (usdm['year'] != 2019) )[0]\n",
    "\n",
    "sesr_test = sesr['sesr'][:,:,TestInd]\n",
    "spi_test  = spi['SPI'][:,:,TestInd]\n",
    "usdm_test = usdm['USDM'][:,:,TestInd]\n",
    "\n",
    "sesr_TrainVal = sesr['sesr'][:,:,TrainValInd]\n",
    "spi_TrainVal  = spi['SPI'][:,:,TrainValInd]\n",
    "usdm_TrainVal = usdm['USDM'][:,:,TrainValInd]\n",
    "\n",
    "# Collect the training and validation datasets. Use 2017, drought in northern plains, as a validation set\n",
    "ValInd = np.where(usdm['year'] == 2017)[0]\n",
    "TrainInd = np.where( (usdm['year'] != 2011) & (usdm['year'] != 2017) & (usdm['year'] != 2019) )[0]\n",
    "\n",
    "sesr_train = sesr['sesr'][:,:,TrainInd]\n",
    "spi_train  = spi['SPI'][:,:,TrainInd]\n",
    "usdm_train = usdm['USDM'][:,:,TrainInd]\n",
    "\n",
    "sesr_val = sesr['sesr'][:,:,ValInd]\n",
    "spi_val  = spi['SPI'][:,:,ValInd]\n",
    "usdm_val = usdm['USDM'][:,:,ValInd]\n",
    "\n",
    "# Transform the data into 1D arrays for easier iterations in the SL learning.\n",
    "I, J, T_train = usdm_train.shape\n",
    "T_val         = usdm_val.shape[-1]\n",
    "T_train_val   = usdm_TrainVal.shape[-1]\n",
    "T_test        = usdm_test.shape[-1]\n",
    "\n",
    "# USDM is the label, therefore is the y vector in the learning algorithms.\n",
    "y_train     = usdm_train.reshape(I*J*T_train, order = 'F')\n",
    "y_val       = usdm_val.reshape(I*J*T_val, order = 'F')\n",
    "y_train_val = usdm_TrainVal.reshape(I*J*T_train_val, order = 'F')\n",
    "y_test      = usdm_test.reshape(I*J*T_test, order = 'F')\n",
    "\n",
    "\n",
    "sesr_train1D     = sesr_train.reshape(I*J*T_train, order = 'F')\n",
    "sesr_val1D       = sesr_val.reshape(I*J*T_val, order = 'F')\n",
    "sesr_train_val1D = sesr_TrainVal.reshape(I*J*T_train_val, order = 'F')\n",
    "sesr_test1D      = sesr_test.reshape(I*J*T_test, order = 'F')\n",
    "\n",
    "spi_train1D     = spi_train.reshape(I*J*T_train, order = 'F')\n",
    "spi_val1D       = spi_val.reshape(I*J*T_val, order = 'F')\n",
    "spi_train_val1D = spi_TrainVal.reshape(I*J*T_train_val, order = 'F')\n",
    "spi_test1D      = spi_test.reshape(I*J*T_test, order = 'F')\n",
    "\n",
    "\n",
    "# Finally, the features are the compination of SESR and SPI\n",
    "# For x, the first column is SESR, the second is SPI. shape[-1] is the number of features\n",
    "x_train     = np.asarray([sesr_train1D, spi_train1D]).T\n",
    "x_val       = np.asarray([sesr_val1D, spi_val1D]).T\n",
    "x_train_val = np.asarray([sesr_train_val1D, spi_train_val1D]).T\n",
    "x_test      = np.asarray([sesr_test1D, spi_test1D]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
